{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18947,"status":"ok","timestamp":1718259681310,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"GPb71T_g3EwE","outputId":"f4e1532f-b0d8-49c8-cf23-0a9a9a9bf467"},"outputs":[],"source":["%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","%pip install matplotlib\n","%pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4190,"status":"ok","timestamp":1718259687710,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"i4fP1VEP3EwF"},"outputs":[],"source":["from pathlib import Path\n","import gc\n","import torch\n","import os\n","import torch\n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer,MeshDataset\n",")\n","from meshgpt_pytorch.data import (\n","    derive_face_edges_from_faces\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893201,"status":"ok","timestamp":1718260580906,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"oja1-j9v3EwF","outputId":"32f7c29b-ff06-4c17-dd15-ce25f018524b"},"outputs":[],"source":["from accelerate import notebook_launcher\n","autoencoder = MeshAutoencoder(\n","    decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,\n","    dim_codebook = 192,\n","    dim_area_embed = 16,\n","    dim_coor_embed = 16,\n","    dim_normal_embed = 16,\n","    dim_angle_embed = 8,\n","    attn_decoder_depth  = 4,\n","    attn_encoder_depth = 2)\n","\n","pkg = torch.load(\"/content/drive/Shareddrives/93 Text to Mesh - Ernest & Marcus/20240612_03/2k_mesh-autoencoder_0.3429.pt\")\n","autoencoder.load_state_dict(pkg['model'], strict = False)\n","\n","dataset = MeshDataset.load(\"/content/drive/Shareddrives/93 Text to Mesh - Ernest & Marcus/20240612_01/datasets/objverse_250f_490.7M_all_17561_labels_568425_5_min_x5_aug.npz\")\n","dataset2 = MeshDataset.load(\"/content/drive/Shareddrives/93 Text to Mesh - Ernest & Marcus/20240612_01/datasets/objverse_250f_98.1M_all_17561_labels_113685_5_min_x1_aug.npz\")\n","dataset.data.extend(dataset2.data)\n","dataset2 = MeshDataset.load(\"/content/drive/Shareddrives/93 Text to Mesh - Ernest & Marcus/20240612_01/datasets/shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")\n","dataset.data.extend(dataset2.data)\n","dataset2 = MeshDataset.load(\"/content/drive/Shareddrives/93 Text to Mesh - Ernest & Marcus/20240612_01/datasets/shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")\n","dataset.data.extend(dataset2.data)\n","dataset.sort_dataset_keys()\n","\n","# autoencoder.commit_loss_weight = 0.5\n","# autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n","#                                                 batch_size=32,\n","#                                                 grad_accum_every =2,\n","#                                                 learning_rate = 1e-4,\n","#                                                 checkpoint_every_epoch=1)\n","# _loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)\n","\n","from torch.utils.data import Dataset\n","import numpy as np\n","from torch.nn.utils.rnn import pad_sequence\n","from tqdm import tqdm\n","from meshgpt_pytorch import (\n","    MeshAutoencoder,\n","    MeshTransformer\n",")\n","\n","transformer = MeshTransformer(\n","    autoencoder,\n","    dim = 768,\n","    coarse_pre_gateloop_depth =2,\n","    fine_pre_gateloop_depth= 2,\n","    attn_depth = 12,\n","    attn_heads = 12,\n","    cross_attn_num_mem_kv = 4,\n","    fine_cross_attend_text = True,\n","    text_cond_with_film = False,\n","    num_sos_tokens = 1,\n","    dropout  = 0.0,\n","    max_seq_len = 1500,\n","    fine_attn_depth = 2,\n","    condition_on_text = True,\n","    gateloop_use_heinsen = False,\n","    text_condition_model_types = \"bge\",\n","    text_condition_cond_drop_prob = 0.0,\n",").cuda()\n","\n","\n","def generate_codes(self, autoencoder : MeshAutoencoder, batch_size = 25):\n","    total_batches = (len(self.data) + batch_size - 1) // batch_size\n","\n","    for i in tqdm(range(0, len(self.data), batch_size), total=total_batches):\n","        batch_data = self.data[i:i+batch_size]\n","\n","        padded_batch_vertices = pad_sequence([item['vertices'] for item in batch_data], batch_first=True, padding_value=autoencoder.pad_id).cuda()\n","        padded_batch_faces = pad_sequence([item['faces'] for item in batch_data], batch_first=True, padding_value=autoencoder.pad_id).cuda()\n","        padded_batch_face_edges = pad_sequence([item['face_edges'] for item in batch_data], batch_first=True, padding_value=autoencoder.pad_id).cuda()\n","\n","        batch_codes = autoencoder.tokenize(\n","            vertices=padded_batch_vertices,\n","            faces=padded_batch_faces,\n","            face_edges=padded_batch_face_edges\n","        )\n","\n","\n","        mask = (batch_codes != autoencoder.pad_id).all(dim=-1)\n","        for item_idx, (item_codes, item_mask) in enumerate(zip(batch_codes, mask)):\n","            item_codes_masked = item_codes[item_mask]\n","            item = batch_data[item_idx]\n","            item['codes'] = item_codes_masked.to(\"cpu\")\n","\n","    self.sort_dataset_keys()\n","    print(f\"[MeshDataset] Generated codes for {len(self.data)} entries\")\n","\n","generate_codes(dataset, autoencoder, 350)\n","dataset.embed_texts(transformer, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKNepVuVM0Pv","outputId":"acd9940a-7d4c-424a-b352-36436243816c"},"outputs":[],"source":["batch_size = 32 # 16 batch = 17-19GB VRAM\n","grad_accum_every = 2\n","rate = 1e-2\n","trainer = MeshTransformerTrainer(model=transformer, warmup_steps=10, grad_accum_every=grad_accum_every,\n","    num_train_steps=100, dataset=dataset, batch_size=batch_size, learning_rate=rate, checkpoint_every_epoch=1)\n","\n","loss = trainer.train(503)\n","print(loss)\n","\n","# pkg = dict( model = transformer.state_dict(), )\n","# torch.save(pkg, str(\"./MeshGPT-transformer_trained.pt\"))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5157660,"sourceId":8617083,"sourceType":"datasetVersion"},{"datasetId":5157661,"sourceId":8617085,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
