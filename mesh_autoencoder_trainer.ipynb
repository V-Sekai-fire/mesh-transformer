{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2e9bbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
      "  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to /tmp/pip-req-build-5ilwomrd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git /tmp/pip-req-build-5ilwomrd\n",
      "  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit b5e74674973de4a97431561d7723d9b29629a695\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.31.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.23.3)\n",
      "Requirement already satisfied: beartype in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.18.5)\n",
      "Requirement already satisfied: classifier-free-guidance-pytorch>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.6.4)\n",
      "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.8.0)\n",
      "Requirement already satisfied: einx[torch]>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.2.2)\n",
      "Requirement already satisfied: ema-pytorch in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.4.8)\n",
      "Requirement already satisfied: local-attention>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.9.1)\n",
      "Requirement already satisfied: gateloop-transformer>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.26.4)\n",
      "Requirement already satisfied: pytorch-custom-utils>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.0.20)\n",
      "Requirement already satisfied: taylor-series-linear-attention>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.1.9)\n",
      "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (2.3.1)\n",
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (2.5.3)\n",
      "Requirement already satisfied: torchtyping in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.1.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (4.66.4)\n",
      "Requirement already satisfied: vector-quantize-pytorch>=1.14.22 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.14.24)\n",
      "Requirement already satisfied: x-transformers>=1.30.6 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.30.16)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (0.4.3)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (6.2.0)\n",
      "Requirement already satisfied: open-clip-torch>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2.24.0)\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.41.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.12.1)\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (2.4.4)\n",
      "Requirement already satisfied: rotary-embedding-torch in /usr/local/lib/python3.10/dist-packages (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.2.18) (0.6.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (4.12.2)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.11.0)\n",
      "Requirement already satisfied: pytorch-warmup in /usr/local/lib/python3.10/dist-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.1.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->meshgpt-pytorch==1.2.18) (12.5.40)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.13.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.5.0)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from torchtyping->meshgpt-pytorch==1.2.18) (4.3.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.18.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2024.5.15)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.25.3)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (1.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (4.0.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.2.18) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2019.11.28)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.19.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (10.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7baeb840",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import gc    \n",
    "import torch\n",
    "import os\n",
    "import torch  \n",
    "from meshgpt_pytorch import (\n",
    "    MeshTransformerTrainer,\n",
    "    MeshAutoencoderTrainer,\n",
    "    MeshAutoencoder,\n",
    "    MeshTransformer,MeshDataset\n",
    ")\n",
    "from meshgpt_pytorch.data import ( \n",
    "    derive_face_edges_from_faces\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27f4fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/text-to-mesh\n"
     ]
    }
   ],
   "source": [
    "%cd /root/text-to-mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce60e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,    \n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ecc8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Loaded 53730 entrys\n",
      "[MeshDataset] Created from 53730 entrys\n",
      "[MeshDataset] Loaded 268650 entrys\n",
      "[MeshDataset] Created from 268650 entrys\n",
      "[MeshDataset] Loaded 2156 entrys\n",
      "[MeshDataset] Created from 2156 entrys\n",
      "[MeshDataset] Loaded 21560 entrys\n",
      "[MeshDataset] Created from 21560 entrys\n",
      "length 346096\n",
      "Tokens: 299.7M\n"
     ]
    }
   ],
   "source": [
    "dataset = MeshDataset.load(\"./objverse_250f_45.9M_3086_labels_53730_10_min_x1_aug.npz\")  \n",
    "dataset2 = MeshDataset.load(\"./objverse_250f_229.7M_3086_labels_268650_10_min_x5_aug.npz\")\n",
    "dataset.data.extend(dataset2.data)  \n",
    "dataset2 = MeshDataset.load(\"./shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")  \n",
    "dataset.data.extend(dataset2.data)  \n",
    "dataset2 = MeshDataset.load(\"./shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")  \n",
    "dataset.data.extend(dataset2.data) \n",
    "dataset.sort_dataset_keys()\n",
    "print(\"length\", len(dataset.data))\n",
    "\n",
    "def format_value(value):\n",
    "    if value >= 1_000_000_000:\n",
    "        return f\"{value / 1_000_000_000:.1f}B\"\n",
    "    elif value >= 1_000_000:\n",
    "        return f\"{value / 1_000_000:.1f}M\"\n",
    "    else:\n",
    "        return f\"{value}\"\n",
    "\n",
    "tokens = 0\n",
    "for item in dataset.data:\n",
    "    tokens += len(item['faces']) * 6 \n",
    "total_tokens = format_value(tokens)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a9cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg = torch.load(\"./checkpoints/mesh-autoencoder.ckpt.epoch_2_avg_loss_0.26642_recon_0.3762_commit_-0.5491.pt\") \n",
    "autoencoder.load_state_dict(pkg['model'])\n",
    "for param in autoencoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bad6ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/480:   0%|          | 2/21631 [00:00<43:00,  8.38it/s, commit_loss=-0.81, loss=0.187, recon_loss=0.349] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/480: 100%|██████████| 21631/21631 [40:34<00:00,  8.88it/s, commit_loss=-0.656, loss=0.222, recon_loss=0.354]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 0.2550648029504936 recon loss: 0.3727: commit_loss -0.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/480: 100%|██████████| 21631/21631 [39:37<00:00,  9.10it/s, commit_loss=0.118, loss=0.471, recon_loss=0.447]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average loss: 0.23449984491546533 recon loss: 0.3665: commit_loss -0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/480: 100%|██████████| 21631/21631 [39:37<00:00,  9.10it/s, commit_loss=-0.668, loss=0.223, recon_loss=0.357]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average loss: 0.23763577267303695 recon loss: 0.3658: commit_loss -0.6407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/480: 100%|██████████| 21631/21631 [39:30<00:00,  9.12it/s, commit_loss=-0.751, loss=0.205, recon_loss=0.356]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 average loss: 0.22675028146773687 recon loss: 0.3631: commit_loss -0.6817          avg loss speed: 0.01564985871192842 epochs left: 4.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/480: 100%|██████████| 21631/21631 [39:43<00:00,  9.07it/s, commit_loss=-0.64, loss=0.227, recon_loss=0.355]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 average loss: 0.21760866906293955 recon loss: 0.3603: commit_loss -0.7134          avg loss speed: 0.0153532972891402 epochs left: 5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/480: 100%|██████████| 21631/21631 [39:51<00:00,  9.04it/s, commit_loss=-0.289, loss=0.327, recon_loss=0.385] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 average loss: 0.2149940043678176 recon loss: 0.3591: commit_loss -0.7207          avg loss speed: 0.012337570033420175 epochs left: 6.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/480: 100%|██████████| 21631/21631 [39:43<00:00,  9.07it/s, commit_loss=-0.676, loss=0.218, recon_loss=0.353]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 average loss: 0.2151656723649066 recon loss: 0.3590: commit_loss -0.7190          avg loss speed: 0.004618645934591381 epochs left: 18.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/480: 100%|██████████| 21631/21631 [39:41<00:00,  9.08it/s, commit_loss=-0.862, loss=0.174, recon_loss=0.346]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 average loss: 0.20642133029906706 recon loss: 0.3562: commit_loss -0.7491          avg loss speed: 0.009501451632820873 epochs left: 9.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/480: 100%|██████████| 21631/21631 [39:53<00:00,  9.04it/s, commit_loss=-0.812, loss=0.183, recon_loss=0.345]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 average loss: 0.19742232761713277 recon loss: 0.3536: commit_loss -0.7809          avg loss speed: 0.01477134139346431 epochs left: 6.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/480: 100%|██████████| 21631/21631 [39:55<00:00,  9.03it/s, commit_loss=-0.643, loss=0.254, recon_loss=0.382]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 average loss: 0.19880290955510385 recon loss: 0.3549: commit_loss -0.7807          avg loss speed: 0.007533533871931619 epochs left: 13.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/480:   1%|          | 148/21631 [00:17<41:11,  8.69it/s, commit_loss=-0.401, loss=0.278, recon_loss=0.358]"
     ]
    }
   ],
   "source": [
    "batch_size=16 # The batch size should be max 64.\n",
    "grad_accum_every =4\n",
    "# So set the maximal batch size (max 64) that your VRAM can handle and then use grad_accum_every to create a effective batch size of 64, e.g  16 * 4 = 64\n",
    "learning_rate = 1e-3 # Start with 1e-3 then at stagnation around 0.35, you can lower it to 1e-4.\n",
    "\n",
    "autoencoder.commit_loss_weight = 0.2 # Set dependant on the dataset size, on smaller datasets, 0.1 is fine, otherwise try from 0.25 to 0.4.a\n",
    "autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n",
    "                                             batch_size=batch_size,\n",
    "                                             grad_accum_every = grad_accum_every,\n",
    "                                             learning_rate = learning_rate,\n",
    "                                             checkpoint_every_epoch=1)\n",
    " \n",
    "loss = autoencoder_trainer.train(480, diplay_graph= True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2cc14",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:13<00:00, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE AVG: 0.0005268551, Min: 0.0000168955, Max: 0.0093237488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch\n",
    "now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "now_safe = now_utc.replace(\":\", \"_\")\n",
    "pkg = dict( model = autoencoder.state_dict(), )\n",
    "filename = f\"./MeshGPT-autoencoder_{now_safe}.pt\"\n",
    "torch.save(pkg, filename)\n",
    "\n",
    " \n",
    "def combind_mesh_with_rows(path, meshes):\n",
    "    all_vertices = []\n",
    "    all_faces = []\n",
    "    vertex_offset = 0\n",
    "    translation_distance = 0.5  \n",
    "    obj_file_content = \"\"\n",
    "    \n",
    "    for row, mesh in enumerate(meshes): \n",
    "        for r, faces_coordinates in enumerate(mesh): \n",
    "            numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)  \n",
    "            numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  \n",
    "            numpy_data[:, 2] += translation_distance * (row / 0.2 - 1)  \n",
    "        \n",
    "            for vertex in numpy_data:\n",
    "                all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "        \n",
    "            for i in range(1, len(numpy_data), 3):\n",
    "                all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n",
    "        \n",
    "            vertex_offset += len(numpy_data)\n",
    "        \n",
    "        obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n",
    "     \n",
    "    with open(path , \"w\") as file:\n",
    "        file.write(obj_file_content)   \n",
    "        \n",
    "from meshgpt_pytorch import MeshAutoencoderTrainer, MeshAutoencoder, MeshDataset, mesh_render\n",
    "import tqdm\n",
    "min_mse, max_mse = float('inf'), float('-inf')\n",
    "min_coords, min_orgs, max_coords, max_orgs = None, None, None, None\n",
    "random_samples, random_samples_pred, all_random_samples = [], [], []\n",
    "total_mse, sample_size = 0.0, 200\n",
    "\n",
    "autoencoder = autoencoder.to(\"cuda\")\n",
    "\n",
    "for item in tqdm.tqdm(dataset.data[:sample_size]):  # Use tqdm.tqdm here\n",
    "    item['faces'] = item['faces'].to(\"cuda\")\n",
    "    item['vertices'] = item['vertices'].to(\"cuda\")\n",
    "    item['face_edges'] = item['face_edges'].to(\"cuda\")\n",
    "    codes = autoencoder.tokenize(vertices=item['vertices'], faces=item['faces'], face_edges=item['face_edges']) \n",
    "\n",
    "    codes = codes.flatten().unsqueeze(0)\n",
    "    codes = codes[:, :codes.shape[-1] // autoencoder.num_quantizers * autoencoder.num_quantizers] \n",
    "\n",
    "    coords, mask = autoencoder.decode_from_codes_to_faces(codes)\n",
    "    orgs = item['vertices'][item['faces']].unsqueeze(0)\n",
    "\n",
    "    mse = torch.mean((orgs.view(-1, 3).cpu() - coords.view(-1, 3).cpu())**2)\n",
    "    total_mse += mse \n",
    "\n",
    "    if mse < min_mse: min_mse, min_coords, min_orgs = mse, coords, orgs\n",
    "    if mse > max_mse: max_mse, max_coords, max_orgs = mse, coords, orgs\n",
    "\n",
    "    if len(random_samples) <= 30:\n",
    "        random_samples.append(coords) \n",
    "    else:\n",
    "        all_random_samples.extend([ random_samples])\n",
    "        random_samples, random_samples_pred = [], []\n",
    "\n",
    "print(f'MSE AVG: {total_mse / sample_size:.10f}, Min: {min_mse:.10f}, Max: {max_mse:.10f}')    \n",
    "combind_mesh_with_rows('./mse_rows.obj', all_random_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.conditioner.text_models[0].model.to(\"cuda\")\n",
    "transformer = transformer.to(\"cuda\")\n",
    "\n",
    "dataset.embed_texts(transformer,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf004b7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    " \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    " \n",
    "batch_size = 2\n",
    "grad_accum_every =4     \n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                  accelerator_kwargs = {\"mixed_precision\" : \"fp16\"}, optimizer_kwargs = { \"eps\": 1e-7} , \n",
    "                                 learning_rate = 1e-3, batch_size=batch_size ,checkpoint_every_epoch = 25) \n",
    "loss = trainer.train(35, stop_at_loss = 0.00005)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be998d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<00:27,  7.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:11<00:00, 17.40it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/mesh_render.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  normal = normal / np.linalg.norm(normal)\n",
      "/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/mesh_render.py:19: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  angle_rad = np.arccos(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))\n",
      "/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/mesh_render.py:19: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle_rad = np.arccos(np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE AVG: 0.0006020016, Min: 0.0000172228, Max: 0.0150029017\n",
      "[Save_rendering] Saved at .\\mse_rows.obj\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "from meshgpt_pytorch import mesh_render \n",
    "\n",
    "min_mse, max_mse = float('inf'), float('-inf')\n",
    "min_coords, min_orgs, max_coords, max_orgs = None, None, None, None\n",
    "random_samples, random_samples_pred, all_random_samples = [], [], []\n",
    "total_mse, sample_size = 0.0, 200\n",
    "\n",
    "random.shuffle(dataset.data)\n",
    "autoencoder = autoencoder.to(\"cuda\")\n",
    "for item in tqdm(dataset.data[:sample_size]):\n",
    "    item['faces'] = item['faces'].to(\"cuda\")\n",
    "    item['vertices'] = item['vertices'].to(\"cuda\")\n",
    "    item['face_edges'] = item['face_edges'].to(\"cuda\")\n",
    "    codes = autoencoder.tokenize(vertices=item['vertices'], faces=item['faces'], face_edges=item['face_edges']) \n",
    "\n",
    "    codes = codes.flatten().unsqueeze(0)\n",
    "    codes = codes[:, :codes.shape[-1] // autoencoder.num_quantizers * autoencoder.num_quantizers] \n",
    " \n",
    "    coords, mask = autoencoder.decode_from_codes_to_faces(codes)\n",
    "    orgs = item['vertices'][item['faces']].unsqueeze(0)\n",
    "\n",
    "    mse = torch.mean((orgs.view(-1, 3).cpu() - coords.view(-1, 3).cpu())**2)\n",
    "    total_mse += mse \n",
    "\n",
    "    if mse < min_mse: min_mse, min_coords, min_orgs = mse, coords, orgs\n",
    "    if mse > max_mse: max_mse, max_coords, max_orgs = mse, coords, orgs\n",
    " \n",
    "    if len(random_samples) <= 30:\n",
    "        random_samples.append((coords, mask)) \n",
    "    else:\n",
    "        all_random_samples.extend([ random_samples])\n",
    "        random_samples, random_samples_pred = [], []\n",
    "\n",
    "print(f'MSE AVG: {total_mse / sample_size:.10f}, Min: {min_mse:.10f}, Max: {max_mse:.10f}')\n",
    "mesh_render.save_rendering(f'.\\mse_rows.obj', all_random_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat()\n",
    "now_safe = now_utc.replace(\":\", \"_\")\n",
    "filename = f\"./MeshGPT-autoencoder_{now_safe}.pt\"\n",
    "pkg = dict( model = autoencoder.state_dict(), ) \n",
    "torch.save(pkg, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
