{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:31:09.323479Z","iopub.status.busy":"2024-06-06T16:31:09.322599Z","iopub.status.idle":"2024-06-06T16:31:30.718560Z","shell.execute_reply":"2024-06-06T16:31:30.717443Z","shell.execute_reply.started":"2024-06-06T16:31:09.323408Z"},"trusted":true},"outputs":[],"source":["%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","%pip install matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:31:36.285258Z","iopub.status.busy":"2024-06-06T16:31:36.284932Z","iopub.status.idle":"2024-06-06T16:31:45.066082Z","shell.execute_reply":"2024-06-06T16:31:45.065241Z","shell.execute_reply.started":"2024-06-06T16:31:36.285228Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path \n","import gc    \n","import torch\n","import os\n","import torch  \n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer,MeshDataset\n",")\n","from meshgpt_pytorch.data import ( \n","    derive_face_edges_from_faces\n",")   \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd /root/text-to-mesh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:31:45.081859Z","iopub.status.busy":"2024-06-06T16:31:45.081213Z","iopub.status.idle":"2024-06-06T16:31:46.271695Z","shell.execute_reply":"2024-06-06T16:31:46.270609Z","shell.execute_reply.started":"2024-06-06T16:31:45.081824Z"},"trusted":true},"outputs":[],"source":["autoencoder = MeshAutoencoder( \n","        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,    \n","        dim_codebook = 192,  \n","        dim_area_embed = 16,\n","        dim_coor_embed = 16, \n","        dim_normal_embed = 16,\n","        dim_angle_embed = 8,\n","    \n","    attn_decoder_depth  = 4,\n","    attn_encoder_depth = 2\n","    ).to(\"cuda\")     "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = MeshDataset.load(\"./objverse_250f_45.9M_3086_labels_53730_10_min_x1_aug.npz\")  \n","dataset2 = MeshDataset.load(\"./objverse_250f_229.7M_3086_labels_268650_10_min_x5_aug.npz\")\n","dataset.data.extend(dataset2.data)  \n","dataset2 = MeshDataset.load(\"./shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")  \n","dataset.data.extend(dataset2.data)  \n","dataset2 = MeshDataset.load(\"./shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")  \n","dataset.data.extend(dataset2.data) \n","dataset.sort_dataset_keys()\n","print(\"length\", len(dataset.data))\n","\n","def format_value(value):\n","    if value >= 1_000_000_000:\n","        return f\"{value / 1_000_000_000:.1f}B\"\n","    elif value >= 1_000_000:\n","        return f\"{value / 1_000_000:.1f}M\"\n","    else:\n","        return f\"{value}\"\n","\n","tokens = 0\n","for item in dataset.data:\n","    tokens += len(item['faces']) * 6 \n","total_tokens = format_value(tokens)\n","print(\"Tokens:\", total_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pkg = torch.load(\"checkpoints/mesh-autoencoder.ckpt.epoch_5_avg_loss_0.17483_recon_0.3439_commit_-0.6763.pt\") \n","# autoencoder.load_state_dict(pkg['model'])\n","# for param in autoencoder.parameters():\n","#     param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size=16 # The batch size should be max 64.\n","grad_accum_every =4\n","# So set the maximal batch size (max 64) that your VRAM can handle and then use grad_accum_every to create a effective batch size of 64, e.g  16 * 4 = 64\n","learning_rate = 1e-3 # Start with 1e-3 then at stagnation around 0.35, you can lower it to 1e-4.\n","\n","autoencoder.commit_loss_weight = 0.2 # Set dependant on the dataset size, on smaller datasets, 0.1 is fine, otherwise try from 0.25 to 0.4.\n","autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n","                                             batch_size=batch_size,\n","                                             grad_accum_every = grad_accum_every,\n","                                             learning_rate = learning_rate,\n","                                             checkpoint_every_epoch=5)\n"," \n","loss = autoencoder_trainer.train(480, diplay_graph= True)   "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:43:39.176615Z","iopub.status.busy":"2024-06-06T16:43:39.176215Z","iopub.status.idle":"2024-06-06T16:43:43.557399Z","shell.execute_reply":"2024-06-06T16:43:43.556476Z","shell.execute_reply.started":"2024-06-06T16:43:39.176582Z"},"trusted":true},"outputs":[],"source":["import datetime\n","import torch\n","now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat()\n","now_safe = now_utc.replace(\":\", \"_\")\n","pkg = dict( model = autoencoder.state_dict(), )\n","filename = f\"./MeshGPT-autoencoder_{now_safe}.pt\"\n","torch.save(pkg, filename)\n","import torch\n","import random\n","from tqdm import tqdm \n","from meshgpt_pytorch import mesh_render \n","\n","min_mse, max_mse = float('inf'), float('-inf')\n","min_coords, min_orgs, max_coords, max_orgs = None, None, None, None\n","random_samples, random_samples_pred, all_random_samples = [], [], []\n","total_mse, sample_size = 0.0, 200\n","\n","random.shuffle(dataset.data)\n","autoencoder = autoencoder.to(\"cuda\")\n","for item in tqdm(dataset.data[:sample_size]):\n","    item['faces'] = item['faces'].to(\"cuda\")\n","    item['vertices'] = item['vertices'].to(\"cuda\")\n","    item['face_edges'] = item['face_edges'].to(\"cuda\")\n","    codes = autoencoder.tokenize(vertices=item['vertices'], faces=item['faces'], face_edges=item['face_edges']) \n","    \n","    codes = codes.flatten().unsqueeze(0)\n","    codes = codes[:, :codes.shape[-1] // autoencoder.num_quantizers * autoencoder.num_quantizers] \n"," \n","    coords, mask = autoencoder.decode_from_codes_to_faces(codes)\n","    orgs = item['vertices'][item['faces']].unsqueeze(0)\n","\n","    mse = torch.mean((orgs.view(-1, 3).cpu() - coords.view(-1, 3).cpu())**2)\n","    total_mse += mse \n","\n","    if mse < min_mse: min_mse, min_coords, min_orgs = mse, coords, orgs\n","    if mse > max_mse: max_mse, max_coords, max_orgs = mse, coords, orgs\n"," \n","    if len(random_samples) <= 30:\n","        random_samples.append((coords, mask)) \n","    else:\n","        all_random_samples.extend([ random_samples])\n","        random_samples, random_samples_pred = [], []\n","\n","print(f'MSE AVG: {total_mse / sample_size:.10f}, Min: {min_mse:.10f}, Max: {max_mse:.10f}')    \n","mesh_render.save_rendering(f'./mse_rows.obj', all_random_samples)\n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:43:43.560111Z","iopub.status.busy":"2024-06-06T16:43:43.559376Z","iopub.status.idle":"2024-06-06T16:43:51.699031Z","shell.execute_reply":"2024-06-06T16:43:51.698098Z","shell.execute_reply.started":"2024-06-06T16:43:43.560073Z"},"trusted":true},"outputs":[],"source":["transformer.conditioner.text_models[0].model.to(\"cuda\")\n","transformer = transformer.to(\"cuda\")\n","\n","dataset.embed_texts(transformer,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[" \n","torch.cuda.empty_cache()\n","gc.collect()  \n"," \n","batch_size = 2\n","grad_accum_every =4     \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n","                                  accelerator_kwargs = {\"mixed_precision\" : \"fp16\"}, optimizer_kwargs = { \"eps\": 1e-7} , \n","                                 learning_rate = 1e-3, batch_size=batch_size ,checkpoint_every_epoch = 25) \n","loss = trainer.train(35, stop_at_loss = 0.00005)   \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import random\n","from tqdm import tqdm \n","from meshgpt_pytorch import mesh_render \n","\n","min_mse, max_mse = float('inf'), float('-inf')\n","min_coords, min_orgs, max_coords, max_orgs = None, None, None, None\n","random_samples, random_samples_pred, all_random_samples = [], [], []\n","total_mse, sample_size = 0.0, 200\n","\n","random.shuffle(dataset.data)\n","autoencoder = autoencoder.to(\"cuda\")\n","for item in tqdm(dataset.data[:sample_size]):\n","    item['faces'] = item['faces'].to(\"cuda\")\n","    item['vertices'] = item['vertices'].to(\"cuda\")\n","    item['face_edges'] = item['face_edges'].to(\"cuda\")\n","    codes = autoencoder.tokenize(vertices=item['vertices'], faces=item['faces'], face_edges=item['face_edges']) \n","\n","    codes = codes.flatten().unsqueeze(0)\n","    codes = codes[:, :codes.shape[-1] // autoencoder.num_quantizers * autoencoder.num_quantizers] \n"," \n","    coords, mask = autoencoder.decode_from_codes_to_faces(codes)\n","    orgs = item['vertices'][item['faces']].unsqueeze(0)\n","\n","    mse = torch.mean((orgs.view(-1, 3).cpu() - coords.view(-1, 3).cpu())**2)\n","    total_mse += mse \n","\n","    if mse < min_mse: min_mse, min_coords, min_orgs = mse, coords, orgs\n","    if mse > max_mse: max_mse, max_coords, max_orgs = mse, coords, orgs\n"," \n","    if len(random_samples) <= 30:\n","        random_samples.append((coords, mask)) \n","    else:\n","        all_random_samples.extend([ random_samples])\n","        random_samples, random_samples_pred = [], []\n","\n","print(f'MSE AVG: {total_mse / sample_size:.10f}, Min: {min_mse:.10f}, Max: {max_mse:.10f}')\n","mesh_render.save_rendering(f'.\\mse_rows.obj', all_random_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat()\n","now_safe = now_utc.replace(\":\", \"_\")\n","filename = f\"./MeshGPT-autoencoder_{now_safe}.pt\"\n","pkg = dict( model = autoencoder.state_dict(), ) \n","torch.save(pkg, filename)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5157660,"sourceId":8617083,"sourceType":"datasetVersion"},{"datasetId":5157661,"sourceId":8617085,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
