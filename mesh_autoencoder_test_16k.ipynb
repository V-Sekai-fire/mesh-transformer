{"cells":[{"cell_type":"code","execution_count":null,"id":"b2e9bbe1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13096,"status":"ok","timestamp":1718255361660,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"b2e9bbe1","outputId":"f4aae7de-2006-4fc2-a174-ebcba19ae865"},"outputs":[],"source":["%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","%pip install matplotlib"]},{"cell_type":"code","execution_count":null,"id":"7baeb840","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718255363914,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"7baeb840","lines_to_next_cell":2},"outputs":[],"source":["from pathlib import Path\n","import gc\n","import torch\n","import os\n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer,MeshDataset\n",")\n","from meshgpt_pytorch.data import (\n","    derive_face_edges_from_faces\n",")"]},{"cell_type":"code","execution_count":null,"id":"655619af","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718255363914,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"655619af"},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"id":"ce60e2b3","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1718255363914,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"ce60e2b3"},"outputs":[],"source":["autoencoder = MeshAutoencoder(\n","        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,\n","        dim_codebook = 192,\n","        dim_area_embed = 16,\n","        dim_coor_embed = 16,\n","        dim_normal_embed = 16,\n","        dim_angle_embed = 8,\n","        attn_decoder_depth  = 4,\n","        attn_encoder_depth = 2)"]},{"cell_type":"code","execution_count":null,"id":"37ecc8ed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53515,"status":"ok","timestamp":1718255417425,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"37ecc8ed","outputId":"55caaae5-c4b4-4739-9ab3-d185ed2542c3"},"outputs":[],"source":["dataset = MeshDataset.load(\"./mesh-transformer-datasets/objverse_250f_229.7M_3086_labels_268650_10_min_x5_aug.npz\")\n","dataset.sort_dataset_keys()\n","print(\"length\", len(dataset.data))\n","\n","def format_value(value):\n","    if value >= 1_000_000_000:\n","        return f\"{value / 1_000_000_000:.1f}B\"\n","    elif value >= 1_000_000:\n","        return f\"{value / 1_000_000:.1f}M\"\n","    else:\n","        return f\"{value}\"\n","\n","tokens = 0\n","for item in dataset.data:\n","    tokens += len(item['faces']) * 6\n","total_tokens = format_value(tokens)\n","print(\"Tokens:\", total_tokens)"]},{"cell_type":"code","execution_count":null,"id":"b3a9cefa","metadata":{"executionInfo":{"elapsed":16640,"status":"ok","timestamp":1718255434061,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"b3a9cefa"},"outputs":[],"source":["pkg = torch.load(\"./mesh-transformer-datasets/16k_autoencoder_229M_0.338.pt\", map_location=torch.device(device))\n","autoencoder.load_state_dict(pkg['model'])\n","for param in autoencoder.parameters():\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"id":"61c2cc14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27946,"status":"ok","timestamp":1718255462001,"user":{"displayName":"Ernest Lee","userId":"17643879017059299399"},"user_tz":420},"id":"61c2cc14","lines_to_next_cell":2,"outputId":"a423d436-4b7b-467d-eae5-5e4de042b84e"},"outputs":[],"source":["import torch\n","\n","def combined_mesh_with_rows(path, meshes):\n","    all_vertices = []\n","    all_faces = []\n","    vertex_offset = 0\n","    translation_distance = 0.5\n","    obj_file_content = \"\"\n","\n","    for row, mesh in enumerate(meshes):\n","        for r, faces_coordinates in enumerate(mesh):\n","            numpy_data = faces_coordinates[0].cpu().numpy().reshape(-1, 3)\n","            numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)\n","            numpy_data[:, 2] += translation_distance * (row / 0.2 - 1)\n","\n","            for vertex in numpy_data:\n","                all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n","\n","            for i in range(1, len(numpy_data), 3):\n","                all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n","\n","            vertex_offset += len(numpy_data)\n","\n","        obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n","\n","    with open(path , \"w\") as file:\n","        file.write(obj_file_content)\n","\n","from meshgpt_pytorch import MeshAutoencoderTrainer, MeshAutoencoder, MeshDataset, mesh_render\n","import tqdm\n","import datetime\n","min_mse, max_mse = float('inf'), float('-inf')\n","min_coords, min_orgs, max_coords, max_orgs = None, None, None, None\n","random_samples, random_samples_pred, all_random_samples = [], [], []\n","total_mse, sample_size = 0.0, 200\n","\n","autoencoder = autoencoder.to(device)\n","\n","for item in tqdm.tqdm(dataset.data[:sample_size]):  # Use tqdm.tqdm here\n","    item['faces'] = item['faces'].to(device)\n","    item['vertices'] = item['vertices'].to(device)\n","    item['face_edges'] = item['face_edges'].to(device)\n","    codes = autoencoder.tokenize(vertices=item['vertices'], faces=item['faces'], face_edges=item['face_edges'])\n","\n","    codes = codes.flatten().unsqueeze(0)\n","    codes = codes[:, :codes.shape[-1] // autoencoder.num_quantizers * autoencoder.num_quantizers]\n","\n","    coords, mask = autoencoder.decode_from_codes_to_faces(codes)\n","    orgs = item['vertices'][item['faces']].unsqueeze(0)\n","\n","    mse = torch.mean((orgs.view(-1, 3).cpu() - coords.view(-1, 3).cpu())**2)\n","    total_mse += mse\n","\n","    if mse < min_mse: min_mse, min_coords, min_orgs = mse, coords, orgs\n","    if mse > max_mse: max_mse, max_coords, max_orgs = mse, coords, orgs\n","\n","    if len(random_samples) <= 30:\n","        random_samples.append(coords)\n","    else:\n","        all_random_samples.extend([ random_samples])\n","        random_samples, random_samples_pred = [], []\n","\n","print(f'MSE AVG: {total_mse / sample_size:.10f}, Min: {min_mse:.10f}, Max: {max_mse:.10f}')\n","combined_mesh_with_rows(f'./mse_rows.obj', all_random_samples)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
