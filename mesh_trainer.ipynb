{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca92161",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# # %%\n",
    "!pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
    "!pip install matplotlib\n",
    "%cd /root/text_to_mesh\n",
    "\n",
    "from pathlib import Path \n",
    "import gc    \n",
    "import torch\n",
    "import os\n",
    "import torch  \n",
    "from meshgpt_pytorch import (\n",
    "    MeshTransformerTrainer,\n",
    "    MeshAutoencoderTrainer,\n",
    "    MeshAutoencoder,\n",
    "    MeshTransformer,MeshDataset\n",
    ")\n",
    "from meshgpt_pytorch.data import ( \n",
    "    derive_face_edges_from_faces\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37770c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
    "        codebook_size =  2048, \n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")     \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    " \n",
    "transformer = MeshTransformer(\n",
    "    autoencoder,\n",
    "    dim = 768,\n",
    "    coarse_pre_gateloop_depth =2,  \n",
    "    fine_pre_gateloop_depth= 2, \n",
    "    attn_depth = 12,  \n",
    "    attn_heads = 12, \n",
    "    fine_cross_attend_text = True,\n",
    "    text_cond_with_film = False,\n",
    "    cross_attn_num_mem_kv = 4,\n",
    "    num_sos_tokens = 1, \n",
    "    dropout  = 0.0,\n",
    "    max_seq_len = 1500, \n",
    "    fine_attn_depth = 2,\n",
    "    condition_on_text = True, \n",
    "    gateloop_use_heinsen = False,\n",
    "    text_condition_model_types = \"bge\", \n",
    "    text_condition_cond_drop_prob = 0.25, \n",
    ").to(\"cuda\")\n",
    "\n",
    "pkg = torch.load(\"./MeshGPT-transformer_trained_base.pt\") \n",
    "transformer.load_state_dict(pkg['model'],strict=False)\n",
    " \n",
    "dataset = MeshDataset.load(\"./labels_885_10x5_21720_mod.npz\") \n",
    "labels = list(set(item['texts'] for item in dataset.data))\n",
    "dataset.generate_codes(autoencoder,150)\n",
    "dataset.data[0].keys() \n",
    "dataset.embed_texts(transformer,1)\n",
    "\n",
    "batch_size =16\n",
    "grad_accum_every =4      \n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                 learning_rate = 1e-4, batch_size=batch_size, checkpoint_every_epoch = 25) \n",
    "\n",
    "total_epochs = 740\n",
    "epochs_per_save = 25\n",
    "\n",
    "for i in range(epochs_per_save, total_epochs + 1, epochs_per_save):\n",
    "    loss = trainer.train(i, stop_at_loss = 0.00005)   \n",
    "    pkg = dict( model = transformer.state_dict(), ) \n",
    "    torch.save(pkg, str(f\"./MeshGPT-transformer_trained_{i}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ff497",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
    "        codebook_size =  2048, \n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")     \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    " \n",
    "transformer = MeshTransformer(\n",
    "    autoencoder,\n",
    "    dim = 768,\n",
    "    coarse_pre_gateloop_depth =2,  \n",
    "    fine_pre_gateloop_depth= 2, \n",
    "    attn_depth = 12,  \n",
    "    attn_heads = 12, \n",
    "    fine_cross_attend_text = True,\n",
    "    text_cond_with_film = False,\n",
    "    cross_attn_num_mem_kv = 4,\n",
    "    num_sos_tokens = 1, \n",
    "    dropout  = 0.0,\n",
    "    max_seq_len = 1500, \n",
    "    fine_attn_depth = 2,\n",
    "    condition_on_text = True, \n",
    "    gateloop_use_heinsen = False,\n",
    "    text_condition_model_types = \"bge\", \n",
    "    text_condition_cond_drop_prob = 0.25, \n",
    ").to(\"cuda\")\n",
    "\n",
    "pkg = torch.load(\"./MeshGPT-transformer_trained_base.pt\") \n",
    "transformer.load_state_dict(pkg['model'],strict=False)\n",
    " \n",
    "dataset = MeshDataset.load(\"./labels_885_10x5_21720_mod.npz\") \n",
    "labels = list(set(item['texts'] for item in dataset.data))\n",
    "dataset.generate_codes(autoencoder,150)\n",
    "dataset.data[0].keys() \n",
    "dataset.embed_texts(transformer,1)\n",
    "\n",
    "batch_size =16\n",
    "grad_accum_every =4      \n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                 learning_rate = 1e-4, batch_size=batch_size, checkpoint_every_epoch = 25) \n",
    "\n",
    "total_epochs = 740\n",
    "epochs_per_save = 25\n",
    "\n",
    "for i in range(epochs_per_save, total_epochs + 1, epochs_per_save):\n",
    "    loss = trainer.train(i, stop_at_loss = 0.00005)   \n",
    "    pkg = dict( model = transformer.state_dict(), ) \n",
    "    torch.save(pkg, str(f\"./MeshGPT-transformer_trained_{i}.pt\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
