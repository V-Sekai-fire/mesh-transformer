{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
            "  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to /tmp/pip-req-build-1a_l6h_l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git /tmp/pip-req-build-1a_l6h_l\n",
            "  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit b5e74674973de4a97431561d7723d9b29629a695\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting accelerate>=0.25.0 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "Collecting huggingface_hub>=0.21.4 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
            "Collecting beartype (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "Collecting classifier-free-guidance-pytorch>=0.6.2 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached classifier_free_guidance_pytorch-0.6.4-py3-none-any.whl (1.4 MB)\n",
            "Collecting einops>=0.7.0 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "Collecting einx[torch]>=0.1.3 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "Collecting ema-pytorch (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached ema_pytorch-0.4.8-py3-none-any.whl (8.4 kB)\n",
            "Collecting local-attention>=1.9.0 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached local_attention-1.9.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting gateloop-transformer>=0.2.2 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached gateloop_transformer-0.2.4-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.26.4)\n",
            "Collecting pytorch-custom-utils>=0.0.9 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached pytorch_custom_utils-0.0.20-py3-none-any.whl (9.0 kB)\n",
            "Collecting taylor-series-linear-attention>=0.1.6 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached taylor_series_linear_attention-0.1.9-py3-none-any.whl (7.0 kB)\n",
            "Collecting torch>=2.1 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "Collecting torch_geometric (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "Collecting torchtyping (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Collecting tqdm (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "Collecting vector-quantize-pytorch>=1.14.22 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached vector_quantize_pytorch-1.14.24-py3-none-any.whl (36 kB)\n",
            "Collecting x-transformers>=1.30.6 (from meshgpt-pytorch==1.2.18)\n",
            "  Using cached x_transformers-1.30.16-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (6.0)\n",
            "Collecting safetensors>=0.3.1 (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18)\n",
            "  Using cached safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting ftfy (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "Collecting open-clip-torch>=2.8.0 (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n",
            "Collecting transformers[torch] (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "Collecting sympy (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18)\n",
            "  Using cached sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "Collecting frozendict (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18)\n",
            "  Using cached frozendict-2.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "Collecting rotary-embedding-torch (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached rotary_embedding_torch-0.6.2-py3-none-any.whl (5.3 kB)\n",
            "Collecting filelock (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18)\n",
            "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18)\n",
            "  Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (4.6.3)\n",
            "Collecting optree (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18)\n",
            "  Using cached optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "Collecting pytorch-warmup (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18)\n",
            "  Using cached pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting networkx (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->meshgpt-pytorch==1.2.18)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "Collecting scipy (from torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Collecting aiohttp (from torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.1.2)\n",
            "Collecting scikit-learn (from torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "Collecting typeguard>=2.11.1 (from torchtyping->meshgpt-pytorch==1.2.18)\n",
            "  Using cached typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
            "Collecting torchvision (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "Collecting regex (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
            "Collecting sentencepiece (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting protobuf (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached protobuf-5.27.1-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "Collecting timm (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.2.18) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2019.11.28)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers[torch]->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (10.3.0)\n",
            "Building wheels for collected packages: meshgpt-pytorch\n",
            "  Building wheel for meshgpt-pytorch (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for meshgpt-pytorch: filename=meshgpt_pytorch-1.2.18-py3-none-any.whl size=26186 sha256=35af8169f87bb4ad60b9ae93efe45a5ce522f8534a882de0fe218a47a1800c96\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gcg_391g/wheels/cd/d8/a5/65f9c136a42f5f2c6d1b5f71985810d6ccfc12a630493aa1c2\n",
            "Successfully built meshgpt-pytorch\n",
            "Installing collected packages: wcwidth, sentencepiece, mpmath, typing-extensions, tqdm, threadpoolctl, sympy, scipy, safetensors, regex, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, multidict, joblib, ftfy, fsspec, frozenlist, frozendict, filelock, einops, beartype, async-timeout, yarl, typeguard, triton, scikit-learn, optree, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, einx, aiosignal, tokenizers, nvidia-cusolver-cu12, aiohttp, transformers, torch_geometric, torch, x-transformers, vector-quantize-pytorch, torchvision, torchtyping, rotary-embedding-torch, pytorch-warmup, local-attention, ema-pytorch, accelerate, timm, taylor-series-linear-attention, pytorch-custom-utils, gateloop-transformer, open-clip-torch, classifier-free-guidance-pytorch, meshgpt-pytorch\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.6\n",
            "    Uninstalling wcwidth-0.2.6:\n",
            "      Successfully uninstalled wcwidth-0.2.6\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
        "%pip install matplotlib\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path \n",
        "import gc    \n",
        "import torch\n",
        "import os\n",
        "import torch\n",
        "from meshgpt_pytorch import (\n",
        "    MeshTransformerTrainer,\n",
        "    MeshAutoencoderTrainer,\n",
        "    MeshAutoencoder,\n",
        "    MeshTransformer,MeshDataset\n",
        ")\n",
        "from meshgpt_pytorch.data import ( \n",
        "    derive_face_edges_from_faces\n",
        ")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /root/mesh-transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from accelerate import notebook_launcher\n",
        "def training_function(num_processes=2):\n",
        "    autoencoder = MeshAutoencoder( \n",
        "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
        "        codebook_size = 2048, \n",
        "        dim_codebook = 192,  \n",
        "        dim_area_embed = 16,\n",
        "        dim_coor_embed = 16, \n",
        "        dim_normal_embed = 16,\n",
        "        dim_angle_embed = 8, \n",
        "        attn_decoder_depth  = 4,\n",
        "        attn_encoder_depth = 2) \n",
        "    \n",
        "    pkg = torch.load(\"./2k_autoencoder_490M_recon_0.3561_commit_-0.8175.pt\")  \n",
        "    autoencoder.load_state_dict(pkg['model'], strict = False) \n",
        "    \n",
        "    dataset = MeshDataset.load(\"./objverse_250f_490.7M_all_17561_labels_568425_5_min_x5_aug.npz\")  \n",
        "    dataset2 = MeshDataset.load(\"./objverse_250f_98.1M_all_17561_labels_113685_5_min_x1_aug.npz\")\n",
        "    dataset.data.extend(dataset2.data)  \n",
        "    dataset2 = MeshDataset.load(\"./shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")  \n",
        "    dataset.data.extend(dataset2.data)  \n",
        "    dataset2 = MeshDataset.load(\"./shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")  \n",
        "    dataset.data.extend(dataset2.data) \n",
        "    dataset.sort_dataset_keys() \n",
        "         \n",
        "    autoencoder.commit_loss_weight = 0.5\n",
        "    autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n",
        "                                                 batch_size=32,\n",
        "                                                 grad_accum_every =2,\n",
        "                                                 learning_rate = 1e-3,\n",
        "                                                 checkpoint_every_epoch=1)  \n",
        "    loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)        \n",
        " \n",
        "args = ()\n",
        "notebook_launcher(training_function, args, num_processes=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5157660,
          "sourceId": 8617083,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5157661,
          "sourceId": 8617085,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
