{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
            "  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to /tmp/pip-req-build-zdh3w9nn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git /tmp/pip-req-build-zdh3w9nn\n",
            "  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit ecf72c716f6378a9bb2191ed884b5ce9428dcc81\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.31.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.4 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.23.3)\n",
            "Requirement already satisfied: beartype in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.18.5)\n",
            "Requirement already satisfied: classifier-free-guidance-pytorch>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.6.4)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.8.0)\n",
            "Requirement already satisfied: einx[torch]>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.3.0)\n",
            "Requirement already satisfied: ema-pytorch in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.4.8)\n",
            "Requirement already satisfied: local-attention>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.9.1)\n",
            "Requirement already satisfied: gateloop-transformer>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.26.4)\n",
            "Requirement already satisfied: pytorch-custom-utils>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.0.20)\n",
            "Requirement already satisfied: taylor-series-linear-attention>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.1.9)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (2.3.1)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (2.5.3)\n",
            "Requirement already satisfied: torchtyping in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (0.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (4.66.4)\n",
            "Requirement already satisfied: vector-quantize-pytorch>=1.14.22 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.14.24)\n",
            "Requirement already satisfied: x-transformers>=1.30.6 in /usr/local/lib/python3.10/dist-packages (from meshgpt-pytorch==1.2.18) (1.30.16)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (6.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (0.4.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (6.2.0)\n",
            "Requirement already satisfied: open-clip-torch>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2.24.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.41.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.12.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.10/dist-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (2.4.4)\n",
            "Requirement already satisfied: rotary-embedding-torch in /usr/local/lib/python3.10/dist-packages (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.2.18) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (4.12.2)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.11.0)\n",
            "Requirement already satisfied: pytorch-warmup in /usr/local/lib/python3.10/dist-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1->meshgpt-pytorch==1.2.18) (12.5.40)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.13.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.5.0)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from torchtyping->meshgpt-pytorch==1.2.18) (4.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.18.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2024.5.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (5.27.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (1.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (4.0.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.2.18) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2019.11.28)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.19.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (10.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2024.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (1.25.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->accelerate) (2019.11.28)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
        "%pip install matplotlib\n",
        "%pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path \n",
        "import gc    \n",
        "import torch\n",
        "import os\n",
        "import torch\n",
        "from meshgpt_pytorch import (\n",
        "    MeshTransformerTrainer,\n",
        "    MeshAutoencoderTrainer,\n",
        "    MeshAutoencoder,\n",
        "    MeshTransformer,MeshDataset\n",
        ")\n",
        "from meshgpt_pytorch.data import ( \n",
        "    derive_face_edges_from_faces\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/mesh-transformer\n"
          ]
        }
      ],
      "source": [
        "%cd /root/mesh-transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from accelerate import notebook_launcher\n",
        "def training_function(num_processes=2):\n",
        "    autoencoder = MeshAutoencoder( \n",
        "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
        "        codebook_size = 2048, \n",
        "        dim_codebook = 192,  \n",
        "        dim_area_embed = 16,\n",
        "        dim_coor_embed = 16, \n",
        "        dim_normal_embed = 16,\n",
        "        dim_angle_embed = 8, \n",
        "        attn_decoder_depth  = 4,\n",
        "        attn_encoder_depth = 2) \n",
        "    \n",
        "    pkg = torch.load(\"./checkpoints/mesh-autoencoder.ckpt.epoch_0_avg_loss_-0.06490_recon_0.3518_commit_-0.8334.pt\")  \n",
        "    autoencoder.load_state_dict(pkg['model'], strict = False) \n",
        "    \n",
        "    dataset = MeshDataset.load(\"./objverse_250f_490.7M_all_17561_labels_568425_5_min_x5_aug.npz\")  \n",
        "    dataset2 = MeshDataset.load(\"./objverse_250f_98.1M_all_17561_labels_113685_5_min_x1_aug.npz\")\n",
        "    dataset.data.extend(dataset2.data)  \n",
        "    dataset2 = MeshDataset.load(\"./shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")  \n",
        "    dataset.data.extend(dataset2.data)  \n",
        "    dataset2 = MeshDataset.load(\"./shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")  \n",
        "    dataset.data.extend(dataset2.data) \n",
        "    dataset.sort_dataset_keys() \n",
        "         \n",
        "    autoencoder.commit_loss_weight = 0.5\n",
        "    autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder ,warmup_steps = 10, dataset = dataset, num_train_steps=100,\n",
        "                                                 batch_size=32,\n",
        "                                                 grad_accum_every =2,\n",
        "                                                 learning_rate = 1e-3,\n",
        "                                                 checkpoint_every_epoch=1)  \n",
        "    _loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)        \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on 4 GPUs.\n",
            "[MeshDataset] Loaded 568425 entrys\n",
            "[MeshDataset] Created from 568425 entrys\n",
            "[MeshDataset] Loaded 568425 entrys\n",
            "[MeshDataset] Created from 568425 entrys\n",
            "[MeshDataset] Loaded 568425 entrys\n",
            "[MeshDataset] Created from 568425 entrys\n",
            "[MeshDataset] Loaded 568425 entrys\n",
            "[MeshDataset] Created from 568425 entrys\n",
            "[MeshDataset] Loaded 113685 entrys\n",
            "[MeshDataset] Created from 113685 entrys\n",
            "[MeshDataset] Loaded 113685 entrys\n",
            "[MeshDataset] Created from 113685 entrys\n",
            "[MeshDataset] Loaded 2156 entrys\n",
            "[MeshDataset] Created from 2156 entrys\n",
            "[MeshDataset] Loaded 113685 entrys\n",
            "[MeshDataset] Created from 113685 entrys\n",
            "[MeshDataset] Loaded 2156 entrys\n",
            "[MeshDataset] Created from 2156 entrys\n",
            "[MeshDataset] Loaded 113685 entrys\n",
            "[MeshDataset] Created from 113685 entrys\n",
            "[MeshDataset] Loaded 2156 entrys\n",
            "[MeshDataset] Created from 2156 entrys\n",
            "[MeshDataset] Loaded 2156 entrys\n",
            "[MeshDataset] Created from 2156 entrys\n",
            "[MeshDataset] Loaded 21560 entrys\n",
            "[MeshDataset] Created from 21560 entrys\n",
            "[MeshDataset] Loaded 21560 entrys\n",
            "[MeshDataset] Created from 21560 entrys\n",
            "[MeshDataset] Loaded 21560 entrys\n",
            "[MeshDataset] Created from 21560 entrys\n",
            "[MeshDataset] Loaded 21560 entrys\n",
            "[MeshDataset] Created from 21560 entrys\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/14445:   0%|          | 1/5514 [00:01<2:30:11,  1.63s/it, commit_loss=-0.804, loss=-0.0283, recon_loss=0.374][rank0]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "[rank2]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "[rank1]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "[rank3]:[W reducer.cpp:1389] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "Epoch 1/14445:  97%|█████████▋| 5328/5514 [36:35<01:16,  2.43it/s, commit_loss=-1, loss=-0.158, recon_loss=0.344]43]]   \n",
            "Epoch 1/14445:  97%|█████████▋| 5329/5514 [36:35<01:09,  2.66it/s, commit_loss=-0.637, loss=0.0245, recon_loss=0.343]]W0612 21:00:04.230000 130603408758592 torch/multiprocessing/spawn.py:145] Terminating process 941 via signal SIGTERM\n",
            "W0612 21:00:04.234000 130603408758592 torch/multiprocessing/spawn.py:145] Terminating process 942 via signal SIGTERM\n",
            "W0612 21:00:04.235000 130603408758592 torch/multiprocessing/spawn.py:145] Terminating process 944 via signal SIGTERM\n",
            "W0612 21:00:34.263000 130603408758592 torch/multiprocessing/spawn.py:153] Unable to shutdown process 941 via SIGTERM , forcefully exiting via SIGKILL\n",
            "W0612 21:00:35.337000 130603408758592 torch/multiprocessing/spawn.py:153] Unable to shutdown process 942 via SIGTERM , forcefully exiting via SIGKILL\n",
            "W0612 21:00:36.564000 130603408758592 torch/multiprocessing/spawn.py:153] Unable to shutdown process 944 via SIGTERM , forcefully exiting via SIGKILL\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] failed (exitcode: 1) local_rank: 2 (pid: 943) of fn: training_function (start_method: fork)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 656, in _poll\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     self._pc.join(-1)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 188, in join\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] \n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] -- Process 2 terminated with the following error:\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] Traceback (most recent call last):\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     fn(i, *args)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 580, in _wrap\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     ret = record(fn)(*args_)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     return f(*args, **kwargs)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/tmp/ipykernel_504/2028672340.py\", line 32, in training_function\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     _loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/trainer.py\", line 344, in train\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     for batch_idx, batch in progress_bar:\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     for obj in iterable:\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\", line 464, in __iter__\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     next_batch = next(dataloader_iter)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     data = self._next_data()\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     return self.collate_fn(data)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/data.py\", line 362, in custom_collate\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     datum = pad_sequence(datum, batch_first = True, padding_value = pad_id)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py\", line 399, in pad_sequence\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695]     return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] RuntimeError: CUDA error: out of memory\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] \n",
            "E0612 21:00:37.713000 130603408758592 torch/distributed/elastic/multiprocessing/api.py:695] \n"
          ]
        },
        {
          "ename": "ChildFailedError",
          "evalue": "\n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-06-12_21:00:02\n  host      : 5f2a0b06308c\n  rank      : 2 (local_rank: 2)\n  exitcode  : 1 (pid: 943)\n  error_file: /tmp/torchelastic_iocikef3/none_ie5fenih/attempt_0/2/error.json\n  traceback : Traceback (most recent call last):\n    File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_504/2028672340.py\", line 32, in training_function\n      _loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)\n    File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/trainer.py\", line 344, in train\n      for batch_idx, batch in progress_bar:\n    File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n      for obj in iterable:\n    File \"/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\", line 464, in __iter__\n      next_batch = next(dataloader_iter)\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n      data = self._next_data()\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n      data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n      return self.collate_fn(data)\n    File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/data.py\", line 362, in custom_collate\n      datum = pad_sequence(datum, batch_first = True, padding_value = pad_id)\n    File \"/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py\", line 399, in pad_sequence\n      return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n  RuntimeError: CUDA error: out of memory\n  CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n  For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n  Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n  \n  \n============================================================",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m ()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/launchers.py:239\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval)\u001b[0m\n\u001b[1;32m    225\u001b[0m             rdzv_endpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaster_addr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m     launch_config \u001b[38;5;241m=\u001b[39m LaunchConfig(\n\u001b[1;32m    227\u001b[0m         min_nodes\u001b[38;5;241m=\u001b[39mnum_nodes,\n\u001b[1;32m    228\u001b[0m         max_nodes\u001b[38;5;241m=\u001b[39mnum_nodes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m         log_line_prefix_template\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHELASTIC_LOG_LINE_PREFIX_TEMPLATE\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    238\u001b[0m     )\n\u001b[0;32m--> 239\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlaunch_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py:132\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py:263\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    256\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    264\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    265\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    266\u001b[0m         )\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
            "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntraining_function FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2024-06-12_21:00:02\n  host      : 5f2a0b06308c\n  rank      : 2 (local_rank: 2)\n  exitcode  : 1 (pid: 943)\n  error_file: /tmp/torchelastic_iocikef3/none_ie5fenih/attempt_0/2/error.json\n  traceback : Traceback (most recent call last):\n    File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 347, in wrapper\n      return f(*args, **kwargs)\n    File \"/tmp/ipykernel_504/2028672340.py\", line 32, in training_function\n      _loss1 = autoencoder_trainer.train(14445,  diplay_graph= False)\n    File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/trainer.py\", line 344, in train\n      for batch_idx, batch in progress_bar:\n    File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1181, in __iter__\n      for obj in iterable:\n    File \"/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\", line 464, in __iter__\n      next_batch = next(dataloader_iter)\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n      data = self._next_data()\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n      data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n    File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n      return self.collate_fn(data)\n    File \"/usr/local/lib/python3.10/dist-packages/meshgpt_pytorch/data.py\", line 362, in custom_collate\n      datum = pad_sequence(datum, batch_first = True, padding_value = pad_id)\n    File \"/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py\", line 399, in pad_sequence\n      return torch._C._nn.pad_sequence(sequences, batch_first, padding_value)\n  RuntimeError: CUDA error: out of memory\n  CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n  For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n  Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n  \n  \n============================================================"
          ]
        }
      ],
      "source": [
        "args = ()\n",
        "notebook_launcher(training_function, args, num_processes=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5157660,
          "sourceId": 8617083,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 5157661,
          "sourceId": 8617085,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
