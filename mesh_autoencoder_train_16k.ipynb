{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e9bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baeb840",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "import gc    \n",
    "import torch\n",
    "import os\n",
    "import torch  \n",
    "from meshgpt_pytorch import (\n",
    "    MeshTransformerTrainer,\n",
    "    MeshAutoencoderTrainer,\n",
    "    MeshAutoencoder,\n",
    "    MeshTransformer,MeshDataset\n",
    ")\n",
    "from meshgpt_pytorch.data import ( \n",
    "    derive_face_edges_from_faces\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/text-to-mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,\n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecc8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeshDataset.load(\"./mesh-transformer-datasets/objverse_250f_490.7M_all_17561_labels_568425_5_min_x5_aug.npz\")  \n",
    "dataset2 = MeshDataset.load(\"./mesh-transformer-datasets/objverse_250f_98.1M_all_17561_labels_113685_5_min_x1_aug.npz\")\n",
    "dataset.data.extend(dataset2.data)  \n",
    "dataset2 = MeshDataset.load(\"./mesh-transformer-datasets/shapenet_250f_2.2M_84_labels_2156_10_min_x1_aug.npz\")  \n",
    "dataset.data.extend(dataset2.data)  \n",
    "dataset2 = MeshDataset.load(\"./mesh-transformer-datasets/shapenet_250f_21.9M_84_labels_21560_10_min_x10_aug.npz\")  \n",
    "dataset.data.extend(dataset2.data) \n",
    "dataset.sort_dataset_keys()\n",
    "print(\"length\", len(dataset.data))\n",
    "\n",
    "def format_value(value):\n",
    "    if value >= 1_000_000_000:\n",
    "        return f\"{value / 1_000_000_000:.1f}B\"\n",
    "    elif value >= 1_000_000:\n",
    "        return f\"{value / 1_000_000:.1f}M\"\n",
    "    else:\n",
    "        return f\"{value}\"\n",
    "\n",
    "tokens = 0\n",
    "for item in dataset.data:\n",
    "    tokens += len(item['faces']) * 6 \n",
    "total_tokens = format_value(tokens)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg = torch.load(\"./2k_autoencoder_490M__recon_0.3665_commit_-0.7556.pt\") \n",
    "autoencoder.load_state_dict(pkg['model'])\n",
    "for param in autoencoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32 # The batch size should be max 64.\n",
    "grad_accum_every =2\n",
    "# So set the maximal batch size (max 64) that your VRAM can handle and then use grad_accum_every to create a effective batch size of 64, e.g  16 * 4 = 64\n",
    "learning_rate = 1e-3 # Start with 1e-3 then at stagnation around 0.35, you can lower it to 1e-4.\n",
    "\n",
    "autoencoder.commit_loss_weight = 0.5 # Set dependant on the dataset size, on smaller datasets, 0.1 is fine, otherwise try from 0.25 to 0.4.a \n",
    " \n",
    "loss = autoencoder_trainer.train(480, diplay_graph= True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d8703",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg = dict( model = autoencoder.state_dict(), ) \n",
    "import datetime\n",
    "# now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat().replace(\":\", \"_\").replace(\"+\", \"_\") \n",
    "#torch.save(pkg, f\"./16k_autoencoder_229M_0.338.pt\")\n",
    "torch.save(pkg, f\"./2k_autoencoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
