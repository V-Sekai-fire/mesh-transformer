{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca92161",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
      "  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to c:\\users\\ernest.lee\\appdata\\local\\temp\\pip-req-build-avrz28q_\n",
      "  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit b5e74674973de4a97431561d7723d9b29629a695\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: accelerate>=0.25.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.31.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.4 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.23.3)\n",
      "Requirement already satisfied: beartype in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.18.5)\n",
      "Requirement already satisfied: classifier-free-guidance-pytorch>=0.6.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.6.4)\n",
      "Requirement already satisfied: einops>=0.7.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.8.0)\n",
      "Requirement already satisfied: einx>=0.1.3 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (0.2.2)\n",
      "Requirement already satisfied: ema-pytorch in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.4.8)\n",
      "Requirement already satisfied: local-attention>=1.9.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.9.1)\n",
      "Requirement already satisfied: gateloop-transformer>=0.2.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.2.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.26.3)\n",
      "Requirement already satisfied: pytorch-custom-utils>=0.0.9 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.0.20)\n",
      "Requirement already satisfied: taylor-series-linear-attention>=0.1.6 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.1.9)\n",
      "Requirement already satisfied: torch>=2.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (2.3.1+cu121)\n",
      "Requirement already satisfied: torch_geometric in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (2.5.3)\n",
      "Requirement already satisfied: torchtyping in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.1.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (4.66.4)\n",
      "Requirement already satisfied: vector-quantize-pytorch>=1.14.22 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.14.24)\n",
      "Requirement already satisfied: x-transformers>=1.30.6 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.30.16)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (0.4.3)\n",
      "Requirement already satisfied: ftfy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (6.2.0)\n",
      "Requirement already satisfied: open-clip-torch>=2.8.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2.24.0)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.41.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.12)\n",
      "Requirement already satisfied: frozendict in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (2.4.4)\n",
      "Requirement already satisfied: rotary-embedding-torch in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.2.18) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (4.12.2)\n",
      "Requirement already satisfied: optree in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.11.0)\n",
      "Requirement already satisfied: pytorch-warmup in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.1.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from tqdm->meshgpt-pytorch==1.2.18) (0.4.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.13.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.9.5)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.5.0)\n",
      "Requirement already satisfied: typeguard>=2.11.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torchtyping->meshgpt-pytorch==1.2.18) (4.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.1->meshgpt-pytorch==1.2.18) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.1->meshgpt-pytorch==1.2.18) (2021.11.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.18.1+cu121)\n",
      "Requirement already satisfied: regex in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2024.5.15)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.25.3)\n",
      "Requirement already satisfied: timm in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (1.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.9.4)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from ftfy->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.2.18) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from sympy->einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from transformers[torch]->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.19.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git 'C:\\Users\\ernest.lee\\AppData\\Local\\Temp\\pip-req-build-avrz28q_'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[WinError 3] The system cannot find the path specified: '/root/text_to_mesh'\n",
      "c:\\Users\\ernest.lee\\Desktop\\text-to-mesh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ernest.lee\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n",
    "%pip install matplotlib\n",
    "\n",
    "%cd /root/text_to_mesh\n",
    "\n",
    "from pathlib import Path \n",
    "import gc    \n",
    "import torch\n",
    "import os\n",
    "import torch  \n",
    "from meshgpt_pytorch import (\n",
    "    MeshTransformerTrainer,\n",
    "    MeshAutoencoderTrainer,\n",
    "    MeshAutoencoder,\n",
    "    MeshTransformer,MeshDataset\n",
    ")\n",
    "from meshgpt_pytorch.data import ( \n",
    "    derive_face_edges_from_faces\n",
    ")\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37770c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Loaded 15170 entrys\n",
      "[MeshDataset] Created from 15170 entrys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:09<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Generated codes for 15170 entrys\n",
      "[MeshDataset] Generated 885 text_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35:   5%|▍         | 367/7585 [00:51<16:44,  7.19it/s, loss=9.91]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m grad_accum_every \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m     \n\u001b[0;32m     47\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MeshTransformerTrainer(model \u001b[38;5;241m=\u001b[39m transformer,warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,grad_accum_every\u001b[38;5;241m=\u001b[39mgrad_accum_every,num_train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, dataset \u001b[38;5;241m=\u001b[39m dataset, \n\u001b[0;32m     48\u001b[0m                                   accelerator_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed_precision\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m}, optimizer_kwargs \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-7\u001b[39m} , \n\u001b[0;32m     49\u001b[0m                                  learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size ,checkpoint_every_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \n\u001b[1;32m---> 50\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_at_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00005\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# pkg = torch.load(\"./MeshGPT-transformer_trained_base.pt\") \u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# transformer.load_state_dict(pkg['model'],strict=False)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\trainer.py:679\u001b[0m, in \u001b[0;36mMeshTransformerTrainer.train\u001b[1;34m(self, num_epochs, stop_at_loss, diplay_graph)\u001b[0m\n\u001b[0;32m    676\u001b[0m maybe_no_sync \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mautocast(), maybe_no_sync(): \n\u001b[1;32m--> 679\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_accum_every)\n\u001b[0;32m    682\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\accelerate\\utils\\operations.py:822\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\accelerate\\utils\\operations.py:810\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:16\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[1;32m---> 16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\meshgpt_pytorch.py:1421\u001b[0m, in \u001b[0;36mMeshTransformer.forward\u001b[1;34m(self, vertices, faces, face_edges, codes, cache, **kwargs)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(codes):\n\u001b[0;32m   1415\u001b[0m     codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mtokenize(\n\u001b[0;32m   1416\u001b[0m         vertices \u001b[38;5;241m=\u001b[39m vertices,\n\u001b[0;32m   1417\u001b[0m         faces \u001b[38;5;241m=\u001b[39m faces,\n\u001b[0;32m   1418\u001b[0m         face_edges \u001b[38;5;241m=\u001b[39m face_edges\n\u001b[0;32m   1419\u001b[0m     )\n\u001b[1;32m-> 1421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_on_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\classifier_free_guidance_pytorch\\classifier_free_guidance_pytorch.py:141\u001b[0m, in \u001b[0;36mclassifier_free_guidance.<locals>.inner\u001b[1;34m(self, cond_scale, rescale_phi, cfg_routed_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cond_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myou cannot do condition scaling when in training mode\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn_maybe_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cond_scale \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid conditioning scale, must be greater or equal to 1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    145\u001b[0m kwargs_without_cond_dropout \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, cond_drop_prob_keyname: \u001b[38;5;241m0.\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\classifier_free_guidance_pytorch\\classifier_free_guidance_pytorch.py:134\u001b[0m, in \u001b[0;36mclassifier_free_guidance.<locals>.inner.<locals>.fn_maybe_with_text\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_text_cond\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn_params:\n\u001b[0;32m    132\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mupdate(raw_text_cond \u001b[38;5;241m=\u001b[39m raw_text_cond)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\meshgpt_pytorch.py:1581\u001b[0m, in \u001b[0;36mMeshTransformer.forward_on_codes\u001b[1;34m(self, codes, return_loss, return_cache, append_eos, cache, texts, text_embeds, cond_drop_prob)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarse_gateloop_block):\n\u001b[0;32m   1579\u001b[0m         face_codes, coarse_gateloop_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoarse_gateloop_block(face_codes, cache \u001b[38;5;241m=\u001b[39m coarse_gateloop_cache)\n\u001b[1;32m-> 1581\u001b[0m     attended_face_codes, coarse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mface_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcoarse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_hiddens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattn_context_kwargs\u001b[49m\n\u001b[0;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1588\u001b[0m     attended_face_codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\x_transformers\\x_transformers.py:1497\u001b[0m, in \u001b[0;36mAttentionLayers.forward\u001b[1;34m(self, x, context, mask, context_mask, attn_mask, self_attn_kv_mask, mems, mem_masks, seq_start_pos, cache, cache_age, return_hiddens, rotary_pos_emb)\u001b[0m\n\u001b[0;32m   1494\u001b[0m         layer_mem \u001b[38;5;241m=\u001b[39m pre_norm(layer_mem)\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1497\u001b[0m     out, inter \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mself_attn_kv_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrotary_pos_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_attn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprev_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_attn_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_mem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_mem_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_intermediates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1499\u001b[0m     out, inter \u001b[38;5;241m=\u001b[39m block(x, context \u001b[38;5;241m=\u001b[39m context, mask \u001b[38;5;241m=\u001b[39m mask, context_mask \u001b[38;5;241m=\u001b[39m context_mask, prev_attn \u001b[38;5;241m=\u001b[39m prev_cross_attn, cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iter_attn_cache, \u001b[38;5;28;01mNone\u001b[39;00m), return_intermediates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\x_transformers\\x_transformers.py:957\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x, context, mask, context_mask, attn_mask, rel_pos, rotary_pos_emb, prev_attn, mem, mem_mask, return_intermediates, cache)\u001b[0m\n\u001b[0;32m    955\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_q(q_input)\n\u001b[0;32m    956\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_k(k_input)\n\u001b[1;32m--> 957\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_v\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_input\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_v) \u001b[38;5;28;01melse\u001b[39;00m k\n\u001b[0;32m    958\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_r(r_input) \u001b[38;5;28;01mif\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_r) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    960\u001b[0m q \u001b[38;5;241m=\u001b[39m rearrange(q, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h \u001b[38;5;241m=\u001b[39m h)\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,    \n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")      \n",
    "\n",
    "pkg = torch.load(\"./16k_autoencoder_229M_0.338.pt\") \n",
    "autoencoder.load_state_dict(pkg['model'])\n",
    "for param in autoencoder.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "dataset = MeshDataset.load(\"./labels_885_10x5_21720_mod.npz\") \n",
    "labels = list(set(item['texts'] for item in dataset.data))\n",
    "dataset.generate_codes(autoencoder,150)\n",
    "dataset.data[0].keys() \n",
    "\n",
    "transformer = MeshTransformer(\n",
    "    autoencoder,\n",
    "    dim = 768,\n",
    "    coarse_pre_gateloop_depth =2,  \n",
    "    fine_pre_gateloop_depth= 2, \n",
    "    attn_depth = 12,  \n",
    "    attn_heads = 12, \n",
    "    fine_cross_attend_text = True,\n",
    "    text_cond_with_film = False,\n",
    "    cross_attn_num_mem_kv = 4,\n",
    "    num_sos_tokens = 1, \n",
    "    dropout  = 0.0,\n",
    "    max_seq_len = 1500, \n",
    "    fine_attn_depth = 2,\n",
    "    condition_on_text = True, \n",
    "    gateloop_use_heinsen = False,\n",
    "    text_condition_model_types = \"bge\", \n",
    "    text_condition_cond_drop_prob = 0.25, \n",
    ").to(\"cuda\")\n",
    "\n",
    "dataset.embed_texts(transformer,1)\n",
    "\n",
    "batch_size = 2\n",
    "grad_accum_every =4     \n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                  accelerator_kwargs = {\"mixed_precision\" : \"fp16\"}, optimizer_kwargs = { \"eps\": 1e-7} , \n",
    "                                 learning_rate = 1e-3, batch_size=batch_size ,checkpoint_every_epoch = 25) \n",
    "loss = trainer.train(35, stop_at_loss = 0.00005)   \n",
    " \n",
    "# pkg = torch.load(\"./MeshGPT-transformer_trained_base.pt\") \n",
    "# transformer.load_state_dict(pkg['model'],strict=False)\n",
    "\n",
    "batch_size =16\n",
    "grad_accum_every =4      \n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                 learning_rate = 1e-4, batch_size=batch_size, checkpoint_every_epoch = 1) \n",
    "\n",
    "total_epochs = 740\n",
    "epochs_per_save = 25\n",
    "\n",
    "for i in range(epochs_per_save, total_epochs + 1, epochs_per_save):\n",
    "    loss = trainer.train(i, stop_at_loss = 0.00005)   \n",
    "    pkg = dict( model = transformer.state_dict(), ) \n",
    "    now_utc = datetime.datetime.now(datetime.timezone.utc).isoformat().replace(\":\", \"_\").replace(\"+\", \"_\")\n",
    "    torch.save(pkg, str(f\"./MeshGPT-transformer_trained_{now_utc}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7ff497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Loaded 15170 entrys\n",
      "[MeshDataset] Created from 15170 entrys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:09<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MeshDataset] Generated codes for 15170 entrys\n"
     ]
    }
   ],
   "source": [
    "autoencoder = MeshAutoencoder( \n",
    "        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,   \n",
    "        codebook_size =  2048, \n",
    "        dim_codebook = 192,  \n",
    "        dim_area_embed = 16,\n",
    "        dim_coor_embed = 16, \n",
    "        dim_normal_embed = 16,\n",
    "        dim_angle_embed = 8,\n",
    "    \n",
    "    attn_decoder_depth  = 4,\n",
    "    attn_encoder_depth = 2\n",
    "    ).to(\"cuda\")     \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    " \n",
    "transformer = MeshTransformer(\n",
    "    autoencoder,\n",
    "    dim = 768,\n",
    "    coarse_pre_gateloop_depth =2,  \n",
    "    fine_pre_gateloop_depth= 2, \n",
    "    attn_depth = 12,  \n",
    "    attn_heads = 12, \n",
    "    fine_cross_attend_text = True,\n",
    "    text_cond_with_film = False,\n",
    "    cross_attn_num_mem_kv = 4,\n",
    "    num_sos_tokens = 1, \n",
    "    dropout  = 0.0,\n",
    "    max_seq_len = 1500, \n",
    "    fine_attn_depth = 2,\n",
    "    condition_on_text = True, \n",
    "    gateloop_use_heinsen = False,\n",
    "    text_condition_model_types = \"bge\", \n",
    "    text_condition_cond_drop_prob = 0.25, \n",
    ").to(\"cuda\")\n",
    "\n",
    "try:\n",
    "    pkg = torch.load(\"./MeshGPT-transformer.pt.pt\")\n",
    "    transformer.load_state_dict(pkg['model'],strict=False)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "dataset = MeshDataset.load(\"./labels_885_10x5_21720_mod.npz\") \n",
    "labels = list(set(item['texts'] for item in dataset.data))\n",
    "dataset.generate_codes(autoencoder,150)\n",
    "dataset.data[0].keys() \n",
    "dataset.embed_texts(transformer,1)\n",
    "batch_size = 16\n",
    "grad_accum_every = 4      \n",
    "epochs_per_save = 1\n",
    "trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n",
    "                                 learning_rate = 1e-4, batch_size=batch_size, checkpoint_every_epoch = epochs_per_save) \n",
    "total_epochs = 740\n",
    "loss = trainer.train(total_epochs, stop_at_loss = 0.00005)   \n",
    "pkg = dict( model = transformer.state_dict(), ) \n",
    "torch.save(pkg, str(f\"./MeshGPT-transformer.pt\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
