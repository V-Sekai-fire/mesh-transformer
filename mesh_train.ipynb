{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:31:09.323479Z","iopub.status.busy":"2024-06-06T16:31:09.322599Z","iopub.status.idle":"2024-06-06T16:31:30.718560Z","shell.execute_reply":"2024-06-06T16:31:30.717443Z","shell.execute_reply.started":"2024-06-06T16:31:09.323408Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","  Cloning https://github.com/MarcusLoppe/meshgpt-pytorch.git to c:\\users\\ernest.lee\\appdata\\local\\temp\\pip-req-build-x2l9l4h0\n","  Resolved https://github.com/MarcusLoppe/meshgpt-pytorch.git to commit b5e74674973de4a97431561d7723d9b29629a695\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: accelerate>=0.25.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.31.0)\n","Requirement already satisfied: huggingface_hub>=0.21.4 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.23.3)\n","Requirement already satisfied: beartype in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.18.5)\n","Requirement already satisfied: classifier-free-guidance-pytorch>=0.6.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.6.4)\n","Requirement already satisfied: einops>=0.7.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.8.0)\n","Requirement already satisfied: einx>=0.1.3 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (0.2.2)\n","Requirement already satisfied: ema-pytorch in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.4.8)\n","Requirement already satisfied: local-attention>=1.9.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.9.1)\n","Requirement already satisfied: gateloop-transformer>=0.2.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.2.4)\n","Requirement already satisfied: numpy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.26.3)\n","Requirement already satisfied: pytorch-custom-utils>=0.0.9 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.0.20)\n","Requirement already satisfied: taylor-series-linear-attention>=0.1.6 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.1.9)\n","Requirement already satisfied: torch>=2.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (2.3.1+cu121)\n","Requirement already satisfied: torch_geometric in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (2.5.3)\n","Requirement already satisfied: torchtyping in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (0.1.4)\n","Requirement already satisfied: tqdm in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (4.66.4)\n","Requirement already satisfied: vector-quantize-pytorch>=1.14.22 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.14.24)\n","Requirement already satisfied: x-transformers>=1.30.6 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from meshgpt-pytorch==1.2.18) (1.30.16)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (24.1)\n","Requirement already satisfied: psutil in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (5.9.8)\n","Requirement already satisfied: pyyaml in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (6.0.1)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from accelerate>=0.25.0->meshgpt-pytorch==1.2.18) (0.4.3)\n","Requirement already satisfied: ftfy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (6.2.0)\n","Requirement already satisfied: open-clip-torch>=2.8.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2.24.0)\n","Requirement already satisfied: transformers[torch] in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.41.2)\n","Requirement already satisfied: sympy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.12)\n","Requirement already satisfied: frozendict in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (2.4.4)\n","Requirement already satisfied: rotary-embedding-torch in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from gateloop-transformer>=0.2.2->meshgpt-pytorch==1.2.18) (0.6.2)\n","Requirement already satisfied: filelock in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.0)\n","Requirement already satisfied: requests in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (4.12.2)\n","Requirement already satisfied: optree in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.11.0)\n","Requirement already satisfied: pytorch-warmup in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from pytorch-custom-utils>=0.0.9->meshgpt-pytorch==1.2.18) (0.1.1)\n","Requirement already satisfied: networkx in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.2.1)\n","Requirement already satisfied: jinja2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (3.1.4)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch>=2.1->meshgpt-pytorch==1.2.18) (2021.4.0)\n","Requirement already satisfied: colorama in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from tqdm->meshgpt-pytorch==1.2.18) (0.4.6)\n","Requirement already satisfied: scipy in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.13.1)\n","Requirement already satisfied: aiohttp in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.9.5)\n","Requirement already satisfied: pyparsing in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (3.1.2)\n","Requirement already satisfied: scikit-learn in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torch_geometric->meshgpt-pytorch==1.2.18) (1.5.0)\n","Requirement already satisfied: typeguard>=2.11.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torchtyping->meshgpt-pytorch==1.2.18) (4.3.0)\n","Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.1->meshgpt-pytorch==1.2.18) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.1->meshgpt-pytorch==1.2.18) (2021.11.0)\n","Requirement already satisfied: torchvision in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.18.1+cu121)\n","Requirement already satisfied: regex in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (2024.5.15)\n","Requirement already satisfied: sentencepiece in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.0)\n","Requirement already satisfied: protobuf in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (4.25.3)\n","Requirement already satisfied: timm in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (1.0.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from aiohttp->torch_geometric->meshgpt-pytorch==1.2.18) (1.9.4)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from ftfy->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.2.13)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from jinja2->torch>=2.1->meshgpt-pytorch==1.2.18) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from requests->huggingface_hub>=0.21.4->meshgpt-pytorch==1.2.18) (2024.6.2)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from scikit-learn->torch_geometric->meshgpt-pytorch==1.2.18) (3.5.0)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from sympy->einx>=0.1.3->einx[torch]>=0.1.3->meshgpt-pytorch==1.2.18) (1.3.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from transformers[torch]->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (0.19.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from torchvision->open-clip-torch>=2.8.0->classifier-free-guidance-pytorch>=0.6.2->meshgpt-pytorch==1.2.18) (10.2.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  Running command git clone --filter=blob:none --quiet https://github.com/MarcusLoppe/meshgpt-pytorch.git 'C:\\Users\\ernest.lee\\AppData\\Local\\Temp\\pip-req-build-x2l9l4h0'\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: matplotlib in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (3.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.23 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=8 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (10.2.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in c:\\users\\ernest.lee\\scoop\\apps\\python\\current\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","%pip install matplotlib\n","from pathlib import Path \n","import gc    \n","import torch\n","import os\n","import torch  \n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer,MeshDataset\n",")\n","from meshgpt_pytorch.data import ( \n","    derive_face_edges_from_faces\n",")   \n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[MeshDataset] Loaded 15170 entrys\n","[MeshDataset] Created from 15170 entrys\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 102/102 [00:17<00:00,  5.72it/s]\n","c:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n","  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"]},{"name":"stdout","output_type":"stream","text":["[MeshDataset] Generated codes for 15170 entrys\n","[MeshDataset] Generated 885 text_embeddings\n"]}],"source":["\n","pkg = torch.load(\"./16k_autoencoder_229M_0.338.pt\", map_location=torch.device(\"cuda\")) \n","autoencoder = MeshAutoencoder( \n","        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,    \n","        dim_codebook = 192,  \n","        dim_area_embed = 16,\n","        dim_coor_embed = 16, \n","        dim_normal_embed = 16,\n","        dim_angle_embed = 8,\n","    \n","    attn_decoder_depth  = 4,\n","    attn_encoder_depth = 2\n","    ).to(\"cuda\")\n","autoencoder.load_state_dict(pkg['model'])\n","\n","transformer = MeshTransformer(\n","    autoencoder,\n","    dim = 768,\n","    coarse_pre_gateloop_depth =2,  \n","    fine_pre_gateloop_depth= 2, \n","    attn_depth = 12,  \n","    attn_heads = 12, \n","    fine_cross_attend_text = True,\n","    text_cond_with_film = False,\n","    cross_attn_num_mem_kv = 4,\n","    num_sos_tokens = 1, \n","    dropout  = 0.0,\n","    max_seq_len = 1500, \n","    fine_attn_depth = 2,\n","    condition_on_text = True, \n","    gateloop_use_heinsen = False,\n","    text_condition_model_types = \"bge\", \n","    text_condition_cond_drop_prob = 0.0, \n",").to(\"cuda\") \n","\n","dataset = MeshDataset.load(\"./labels_885_10x5_21720_mod.npz\") \n","labels = list(set(item['texts'] for item in dataset.data))\n","dataset.generate_codes(autoencoder,150)\n","dataset.data[0].keys() \n","dataset.embed_texts(transformer,1)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/35:   0%|          | 0/948 [00:00<?, ?it/s]c:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\backends\\cuda\\__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n","  warnings.warn(\n","Epoch 1/35:   6%|▌         | 58/948 [00:36<09:14,  1.61it/s, loss=9.78]\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 1.31 GiB. GPU ","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m grad_accum_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m     \n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MeshTransformerTrainer(model \u001b[38;5;241m=\u001b[39m transformer,warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,grad_accum_every\u001b[38;5;241m=\u001b[39mgrad_accum_every,num_train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, dataset \u001b[38;5;241m=\u001b[39m dataset, \n\u001b[0;32m      4\u001b[0m                                  learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size ,checkpoint_every_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \n\u001b[1;32m----> 5\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_at_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.00005\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MeshTransformerTrainer(model \u001b[38;5;241m=\u001b[39m transformer,warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,grad_accum_every\u001b[38;5;241m=\u001b[39mgrad_accum_every,num_train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, dataset \u001b[38;5;241m=\u001b[39m dataset, \n\u001b[0;32m      8\u001b[0m                                  learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size ,checkpoint_every_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m) \n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;241m740\u001b[39m, stop_at_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00005\u001b[39m)   \n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\trainer.py:679\u001b[0m, in \u001b[0;36mMeshTransformerTrainer.train\u001b[1;34m(self, num_epochs, stop_at_loss, diplay_graph)\u001b[0m\n\u001b[0;32m    676\u001b[0m maybe_no_sync \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last \u001b[38;5;28;01melse\u001b[39;00m nullcontext\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mautocast(), maybe_no_sync(): \n\u001b[1;32m--> 679\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_accum_every)\n\u001b[0;32m    682\u001b[0m current_loss \u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\meshgpt_pytorch.py:1421\u001b[0m, in \u001b[0;36mMeshTransformer.forward\u001b[1;34m(self, vertices, faces, face_edges, codes, cache, **kwargs)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(codes):\n\u001b[0;32m   1415\u001b[0m     codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mtokenize(\n\u001b[0;32m   1416\u001b[0m         vertices \u001b[38;5;241m=\u001b[39m vertices,\n\u001b[0;32m   1417\u001b[0m         faces \u001b[38;5;241m=\u001b[39m faces,\n\u001b[0;32m   1418\u001b[0m         face_edges \u001b[38;5;241m=\u001b[39m face_edges\n\u001b[0;32m   1419\u001b[0m     )\n\u001b[1;32m-> 1421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_on_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\classifier_free_guidance_pytorch\\classifier_free_guidance_pytorch.py:141\u001b[0m, in \u001b[0;36mclassifier_free_guidance.<locals>.inner\u001b[1;34m(self, cond_scale, rescale_phi, cfg_routed_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cond_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myou cannot do condition scaling when in training mode\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn_maybe_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m cond_scale \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid conditioning scale, must be greater or equal to 1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    145\u001b[0m kwargs_without_cond_dropout \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, cond_drop_prob_keyname: \u001b[38;5;241m0.\u001b[39m}\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\classifier_free_guidance_pytorch\\classifier_free_guidance_pytorch.py:134\u001b[0m, in \u001b[0;36mclassifier_free_guidance.<locals>.inner.<locals>.fn_maybe_with_text\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_text_cond\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn_params:\n\u001b[0;32m    132\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mupdate(raw_text_cond \u001b[38;5;241m=\u001b[39m raw_text_cond)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\meshgpt_pytorch\\meshgpt_pytorch.py:1714\u001b[0m, in \u001b[0;36mMeshTransformer.forward_on_codes\u001b[1;34m(self, codes, return_loss, return_cache, append_eos, cache, texts, text_embeds, cond_drop_prob)\u001b[0m\n\u001b[0;32m   1710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits, next_cache\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[1;32m-> 1714\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb n c -> b c n\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_id\u001b[49m\n\u001b[0;32m   1718\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ce_loss\n","File \u001b[1;32mc:\\Users\\ernest.lee\\scoop\\apps\\python\\current\\Lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.31 GiB. GPU "]}],"source":["batch_size = 16\n","grad_accum_every = 4     \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n","                                 learning_rate = 1e-3, batch_size=batch_size ,checkpoint_every_epoch = 25) \n","loss = trainer.train(35, stop_at_loss = 0.00005)   \n","\n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=grad_accum_every,num_train_steps=100, dataset = dataset, \n","                                 learning_rate = 1e-4, batch_size=batch_size ,checkpoint_every_epoch = 25) \n","loss = trainer.train(740, stop_at_loss = 0.00005)   "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pkg = dict( model = transformer.state_dict(), ) \n","torch.save(pkg, str(\"./MeshGPT-transformer_trained.pt\"))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5157660,"sourceId":8617083,"sourceType":"datasetVersion"},{"datasetId":5157661,"sourceId":8617085,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
