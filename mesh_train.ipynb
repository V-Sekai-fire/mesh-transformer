{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-06T16:31:09.323479Z","iopub.status.busy":"2024-06-06T16:31:09.322599Z","iopub.status.idle":"2024-06-06T16:31:30.718560Z","shell.execute_reply":"2024-06-06T16:31:30.717443Z","shell.execute_reply.started":"2024-06-06T16:31:09.323408Z"},"trusted":true},"outputs":[],"source":["%pip install git+https://github.com/MarcusLoppe/meshgpt-pytorch.git\n","%pip install matplotlib\n","from pathlib import Path \n","import gc    \n","import torch\n","import os\n","import torch  \n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer,MeshDataset\n",")\n","from meshgpt_pytorch.data import ( \n","    derive_face_edges_from_faces\n",")   \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","pkg = torch.load(\"./16k_autoencoder_229M_0.338.pt\", map_location=torch.device(\"cuda\")) \n","autoencoder = MeshAutoencoder( \n","        decoder_dims_through_depth =  (128,) * 6 + (192,) * 12 + (256,) * 24 + (384,) * 6,    \n","        dim_codebook = 192,  \n","        dim_area_embed = 16,\n","        dim_coor_embed = 16, \n","        dim_normal_embed = 16,\n","        dim_angle_embed = 8,\n","    \n","    attn_decoder_depth  = 4,\n","    attn_encoder_depth = 2\n","    ).to(\"cuda\")\n","autoencoder.load_state_dict(pkg['model'])\n","\n","transformer = MeshTransformer(\n","    autoencoder,\n","    dim = 768,\n","    coarse_pre_gateloop_depth =2,  \n","    fine_pre_gateloop_depth= 2, \n","    attn_depth = 12,  \n","    attn_heads = 12, \n","    fine_cross_attend_text = True,\n","    text_cond_with_film = False,\n","    cross_attn_num_mem_kv = 4,\n","    num_sos_tokens = 1, \n","    dropout  = 0.0,\n","    max_seq_len = 1500, \n","    fine_attn_depth = 2,\n","    condition_on_text = True, \n","    gateloop_use_heinsen = False,\n","    text_condition_model_types = \"bge\", \n","    text_condition_cond_drop_prob = 0.0, \n",").to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd C:/Users/ernest.lee/OneDrive/Desktop/text-to-mesh"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","datasets = [\n","    \"labels_885_10x5_21720_mod.npz\",\n","    # \"objverse_250f_45.9M_3086_labels_53730_10_min_x1_aug.npz\",\n","    # \"objverse_250f_229.7M_3086_labels_268650_10_min_x5_aug.npz\"\n","]\n","\n","dataset = None  # Initialize dataset variable\n","\n","for ds in datasets:\n","    if dataset is None:\n","        dataset = MeshDataset.load(ds)\n","    else:\n","        temp_dataset = MeshDataset.load(ds)\n","        dataset.data.extend(temp_dataset.data)\n","\n","dataset.sort_dataset_keys()\n","batch_size = 16\n","grad_accum_every = 4\n","\n","rate = 0.5\n","\n","trainer = MeshTransformerTrainer(model=transformer, warmup_steps=10, grad_accum_every=grad_accum_every,\n","                                 num_train_steps=100, dataset=dataset, batch_size=batch_size, learning_rate=rate, checkpoint_every_epoch=1)\n","EARLY_STOP_LOSS = 0.00005\n","for epoch in range(35):\n","    print(f\"Learning rate is {rate}\")\n","    optimizer = optim.SGD(trainer.model.parameters(), lr=rate)\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n","    loss = trainer.train(1, stop_at_loss = EARLY_STOP_LOSS)\n","    if loss <= EARLY_STOP_LOSS:\n","        break\n","    scheduler.step(loss) \n","    for param_group in optimizer.param_groups:\n","        rate = param_group['lr']\n","    trainer = MeshTransformerTrainer(model=transformer, warmup_steps=10, grad_accum_every=grad_accum_every,\n","                                    num_train_steps=100, dataset=dataset, learning_rate=rate, batch_size=batch_size, checkpoint_every_epoch=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pkg = dict( model = transformer.state_dict(), ) \n","torch.save(pkg, str(\"./MeshGPT-transformer_trained.pt\"))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5157660,"sourceId":8617083,"sourceType":"datasetVersion"},{"datasetId":5157661,"sourceId":8617085,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
